# # Use a pipeline as a high-level helper
# from transformers import pipeline

# pipe = pipeline("text-classification", model="KoalaAI/OffensiveSpeechDetector")
# from transformers import AutoTokenizer, AutoModelForSequenceClassification

# tokenizer = AutoTokenizer.from_pretrained("KoalaAI/OffensiveSpeechDetector")
# model = AutoModelForSequenceClassification.from_pretrained(
#     "KoalaAI/OffensiveSpeechDetector")

# Run only when the model is again needed to download
